<!DOCTYPE html> <html lang="ru"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Ускорение потоков данных | Александр Межов </title> <meta name="author" content="Александр Межов"> <meta name="description" content="Как правило мы находимся в условиях, когда за короткий срок нужно выдать максимум функциональности, обеспечив при этом должный уровень производительности приложения. И если функциональным требованиям уделяют основное внимание, то вопрос производительности воспринимают как само собой разумеющееся. А что делать, если сроки сжаты до предела, уже имеется какой-то рабочий прототип, а нагрузка к моменту основного релиза обещает вырасти в десятки раз? В такой момент мы хотим найти простое решение, которое избавит нас от большей части проблем."> <meta name="keywords" content="architecture, development, blog, Mezhov, Межов"> <meta property="og:site_name" content="Александр Межов"> <meta property="og:type" content="article"> <meta property="og:title" content="Ускорение потоков данных"> <meta property="og:url" content="https://alexmas.github.io//blog/2024/data-flow-speeding-up/"> <meta property="og:description" content="Как правило мы находимся в условиях, когда за короткий срок нужно выдать максимум функциональности, обеспечив при этом должный уровень производительности приложения. И если функциональным требованиям уделяют основное внимание, то вопрос производительности воспринимают как само собой разумеющееся. А что делать, если сроки сжаты до предела, уже имеется какой-то рабочий прототип, а нагрузка к моменту основного релиза обещает вырасти в десятки раз? В такой момент мы хотим найти простое решение, которое избавит нас от большей части проблем."> <meta property="og:image" content="https://alexmas.github.io//assets/img/blog/2024/2024-12-03-data-flow-speeding-up.jpeg"> <meta property="og:locale" content="ru"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Ускорение потоков данных"> <meta name="twitter:description" content="Как правило мы находимся в условиях, когда за короткий срок нужно выдать максимум функциональности, обеспечив при этом должный уровень производительности приложения. И если функциональным требованиям уделяют основное внимание, то вопрос производительности воспринимают как само собой разумеющееся. А что делать, если сроки сжаты до предела, уже имеется какой-то рабочий прототип, а нагрузка к моменту основного релиза обещает вырасти в десятки раз? В такой момент мы хотим найти простое решение, которое избавит нас от большей части проблем."> <meta name="twitter:image" content="https://alexmas.github.io//assets/img/blog/2024/2024-12-03-data-flow-speeding-up.jpeg"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Александр Межов"
        },
        "url": "https://alexmas.github.io//blog/2024/data-flow-speeding-up/",
        "@type": "BlogPosting",
        "description": "Как правило мы находимся в условиях, когда за короткий срок нужно выдать максимум функциональности, обеспечив при этом
должный уровень производительности приложения. И если функциональным требованиям уделяют основное внимание, то вопрос
производительности воспринимают как само собой разумеющееся. А что делать, если сроки сжаты до предела, уже имеется
какой-то рабочий прототип, а нагрузка к моменту основного релиза обещает вырасти в десятки раз? В такой момент мы хотим
найти простое решение, которое избавит нас от большей части проблем.",
        "headline": "Ускорение потоков данных",
        
        "sameAs": "https://t.me/arch_and_dev",
        
        "name": "Александр Межов",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?27787be15f1341be1c13406838f8df52"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://alexmas.github.io//blog/2024/data-flow-speeding-up/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Александр</span> Межов </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Обо мне </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Архитектоника в ИТ </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Публикации и выступления </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Ускорение потоков данных</h1> <p class="post-meta"> </p> <p class="post-tags"> <a href="/blog/2024"><i class="fa-solid fa-calendar fa-sm"></i> 2024</a>-12-20   ·   <a href="/blog/tag/conf"> <i class="fa-solid fa-hashtag fa-sm"></i> conf</a>   <a href="/blog/tag/arch"> <i class="fa-solid fa-hashtag fa-sm"></i> arch</a>   ·   <a href="/blog/category/article"> <i class="fa-solid fa-tag fa-sm"></i> article</a> </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"><a href="#%D0%BF%D1%80%D0%B8%D1%91%D0%BC-1-%D1%80%D0%B0%D1%81%D1%88%D0%B8%D1%80%D0%B5%D0%BD%D0%B8%D0%B5-%D0%BA%D0%BE%D0%BD%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0">Приём №1: Расширение контекста</a></li> <li class="toc-entry toc-h2"><a href="#%D0%BF%D1%80%D0%B8%D1%91%D0%BC-2-%D1%82%D0%B8%D0%BF%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F-%D1%81%D0%BE%D0%B1%D1%8B%D1%82%D0%B8%D0%B9">Приём №2: Типизация событий</a></li> <li class="toc-entry toc-h2"><a href="#%D0%BF%D1%80%D0%B8%D1%91%D0%BC-3-%D0%BA%D0%BE%D0%BD%D0%B2%D0%B5%D0%B9%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F-%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D0%B9">Приём №3: Конвейеризация вычислений</a></li> <li class="toc-entry toc-h2"> <a href="#%D0%BF%D1%80%D0%B8%D1%91%D0%BC-4-%D1%80%D0%B0%D1%81%D0%BF%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D0%B8%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5-%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D0%B9">Приём №4: Распараллеливание вычислений</a> <ul> <li class="toc-entry toc-h3"><a href="#%D1%80%D0%B0%D1%81%D0%BF%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D0%B8%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5-%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D0%B9-%D0%B2-log-based-%D0%B1%D1%80%D0%BE%D0%BA%D0%B5%D1%80%D0%B0%D1%85">Распараллеливание вычислений в Log-based-брокерах</a></li> <li class="toc-entry toc-h3"><a href="#%D1%80%D0%B0%D1%81%D0%BF%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D0%B8%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5-%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D0%B9-%D0%B2-queue-based-%D0%B1%D1%80%D0%BE%D0%BA%D0%B5%D1%80%D0%B0%D1%85">Распараллеливание вычислений в Queue-based-брокерах</a></li> </ul> </li> <li class="toc-entry toc-h2"><a href="#%D0%BF%D1%80%D0%B8%D1%91%D0%BC-5-%D0%BB%D0%BE%D0%BA%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85">Приём №5: Локальность данных</a></li> <li class="toc-entry toc-h2"><a href="#%D0%B7%D0%B0%D0%BA%D0%BB%D1%8E%D1%87%D0%B5%D0%BD%D0%B8%D0%B5">Заключение</a></li> </ul> </div> <hr> <div id="markdown-content"> <p>Как правило мы находимся в условиях, когда за короткий срок нужно выдать максимум функциональности, обеспечив при этом должный уровень производительности приложения. И если функциональным требованиям уделяют основное внимание, то вопрос производительности воспринимают как само собой разумеющееся. А что делать, если сроки сжаты до предела, уже имеется какой-то рабочий прототип, а нагрузка к моменту основного релиза обещает вырасти в десятки раз? В такой момент мы хотим найти простое решение, которое избавит нас от большей части проблем.</p> <p><img src="/assets/img/blog/2024/2024-12-03-data-flow-speeding-up.jpeg" alt=""></p> <p>Обобщив свой опыт я выделил пять простых и практичных архитектурных приемов, которые позволяют кратно ускорить потоки данных.</p> <ul> <li>Расширение контекста</li> <li>Типизация событий</li> <li>Конвейеризация вычислений</li> <li>Распараллеливание вычислений</li> <li>Локальность данных</li> </ul> <p>Далее я раскрою суть и условия применимости каждого приема.</p> <p>Данная статья является текстовым вариантом моего <a href="https://techleadconf.ru/moscow/2024/abstracts/13138" rel="external nofollow noopener" target="_blank">доклада</a> с конференции <a href="https://teamleadconf.ru/moscow/2024" rel="external nofollow noopener" target="_blank">TeamLeadConf 2024</a>.</p> <h2 id="приём-1-расширение-контекста">Приём №1: Расширение контекста</h2> <blockquote> <p>Контекст события ДОЛЖЕН содержать необходимую и достаточную информацию для его обработки, ЕСЛИ ожидаемый поток событий не приводит к превышению лимитов по выделенным ресурсам.</p> </blockquote> <p>Под <em>событием</em> подразумеваю какой-то сигнал в информационной системе; а под <em>контекстом</em> - данные, которые с ним связаны. Контекст используется при обработке события. Физическое представление события, передаваемое по сети, буду называть <em>сообщением</em>.</p> <p>Если данных контекста недостаточно, обработчик вынужден запрашивать их извне: из базы данных, у внешних служб и т.п. Обычно такое происходит, когда хотят минимизировать размер сообщения. Например, в сообщении вместо содержимого документа передается только его идентификатор.</p> <p>При таком подходе возможны две проблемы. Во-первых, появляется альтернативный канал связи, что провоцирует гонку по данным и увеличивает требования к хранилищу данных (см. <a href="https://en.wikipedia.org/wiki/Linearizability" rel="external nofollow noopener" target="_blank">Linearizability</a> и <a href="http://www.cs.utexas.edu/~lorenzo/corsi/cs380d/papers/SessionGuaranteesBayou.pdf" rel="external nofollow noopener" target="_blank">Read Your Writes</a>). Во-вторых, время, которое тратится на восстановление нужного контекста, гарантированно снижает производительность обработчика, особенно в момент нагрузки на систему.</p> <p>Резюмируя, скажу так: расширяйте контекст события, если это не приведет к недопустимой нагрузке на сетевую и дисковую подсистему. Для этого проанализируйте существующий или возможный поток данных: интенсивность возникновения событий и размер сообщений.</p> <h2 id="приём-2-типизация-событий">Приём №2: Типизация событий</h2> <blockquote> <p>События ДОЛЖНЫ направляться в разные топики, ЕСЛИ события явно ИЛИ неявно относятся к разным типам, И ЕСЛИ тип события можно определить перед отправкой.</p> </blockquote> <p>Вроде всё понятно, но есть коварный случай – <em>неявная типизация</em>. Это тот случай, когда реально разные типы событий попадают в один топик и обрабатываются одним и тем же обработчиком. Казалось бы, бред! Но в реальности такое можно увидеть достаточно часто. В основном это вызвано недостаточным знанием предметной области.</p> <p>Если мы недостаточно знаем предметную область, то можем сделать <em>ложное обобщение</em>. Например, для логически разных событий использовать универсальную структуру данных. Об этом же предостерегает и Роберт Мартин в книге “Чистая архитектура” (см. главу “Ложное дублирование”).</p> <p>В чем же основной недостаток иметь один топик для разных типов событий? В первую очередь - это <em>невозможность контроля в распределении ресурсов</em>. Разные типы событий могут иметь разную частоту возникновения, разную скорость обработки. Скорей всего, для наиболее частотных и/или медленно обрабатываемых событий вы захотите выделить больше ресурсов для их обработки.</p> <p>Итак, как же выявить неявную типизацию? Можно выделить следующие отличительные признаки.</p> <ol> <li> <p>Контекст события уже на этапе публикации содержит какой-то ключ-классификатор (один или несколько атрибутов), по которому можно судить о типе события.</p> </li> <li> <p>Алгоритм обработчика события имеет ветвление, которое производится по некоторым атрибутам контекста события. При этом логика обработки каждой ветки существенно разнится. В этом случае можно говорить, что типизация событий производится на стороне получателя.</p> </li> <li> <p>Код обработчика не имеет ветвлений, но время обработки событий существенно варьируется. В этом случае можно говорить о вариативной <a href="https://en.wikipedia.org/wiki/Big_O_notation" rel="external nofollow noopener" target="_blank">вычислительной сложности</a> обработки. Как правило, такое происходит, если обработчик делегирует основную работу внешнему компоненту. Если так, то см. код внешнего компонента и п. 2.</p> </li> </ol> <h2 id="приём-3-конвейеризация-вычислений">Приём №3: Конвейеризация вычислений</h2> <blockquote> <p>Обработчик события ДОЛЖЕН быть поделен на стадии, где каждая стадия – отдельный топик, ЕСЛИ выполнение следующей стадии зависит от предыдущей, И ЕСЛИ время выполнения каждой стадии ощутимо большое.</p> </blockquote> <p>Иначе говоря, мы рассматриваем ситуацию, когда алгоритм обработки состоит из <em>нескольких стадий</em>, где выходные данные одной являются входными для другой - следующей (или следующих в случае, если есть условия выбора следующей стадии). И при этом каждая стадия вносит <em>существенный вклад</em> в общее время обработки. В этом случае следует задуматься о конвейеризации и для каждой стадии конвейера предусмотреть отдельный тип события и топик.</p> <p>Почему это должно ускорить поток данных? Тут следует начать с того, что конвейер позволяет осуществлять <em>внеочередное исполнение</em>. Как это происходит, лучше посмотреть на простом арифметическом примере. Допустим, наш алгоритм состоит из двух стадий: <code class="language-plaintext highlighter-rouge">A</code> и <code class="language-plaintext highlighter-rouge">B</code>; а в очереди находится два события: <code class="language-plaintext highlighter-rouge">E1</code> и <code class="language-plaintext highlighter-rouge">E2</code>.</p> <p>Если у нас один обработчик, который последовательно выполняет все стадии, общее время обработки двух событий будет равно сумме задержек на всех этапах: <code class="language-plaintext highlighter-rouge">Ts=A(E1)+B(E1)+A(E2)+B(E2)</code>.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>E1: A(E1) -&gt; B(E1) -&gt;
E2: ----------------&gt; A(E2) -&gt; B(E2)
</code></pre></div></div> <p>Если у нас конвейерная обработка, т.е. стадии <code class="language-plaintext highlighter-rouge">A</code> и <code class="language-plaintext highlighter-rouge">B</code> выполняют разные обработчики, то для разных событий они могут работать параллельно и независимо друг от друга. И в таком случае общее время обработки двух событий будет равно сумме: <code class="language-plaintext highlighter-rouge">Tp=A(E1)+max(B(E1),A(E2))+B(E2)</code>. Не трудно увидеть, что <code class="language-plaintext highlighter-rouge">Ts&gt;Tp</code>.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>E1: A(E1) -&gt; B(E1)
E2: -------&gt; A(E2) -&gt; B(E2)
</code></pre></div></div> <p>Отдельно стоит отметить тот случай, когда решение об окончании обработки можно принять на <em>ранних стадиях</em>, досрочно закончив весь цикл, откинув ненужных “хвост” конвейера.</p> <p>А теперь, отбросив всю эту теорию, приведу пару практических примеров для закрепления материала (делитесь в комментариях своими более сложными и интересными кейсами).</p> <ul> <li> <p>Проверка возможности выполнения обработки и обработка. Например, проверяем счет клиента, а уже затем формируем для него коммерческое предложение.</p> </li> <li> <p>Подготовка к обработке данных и обработка. Например, перед формированием отчета аккумулируем всех необходимые данные в одном месте.</p> </li> </ul> <h2 id="приём-4-распараллеливание-вычислений">Приём №4: Распараллеливание вычислений</h2> <blockquote> <p>События в топике ДОЛЖНЫ обрабатываться параллельно, ЕСЛИ не важен порядок их обработки.</p> </blockquote> <p>Вот с такого простого и очевидного утверждения начинается долгая история.</p> <p>Когда мы говорим о распараллеливании, нужно помнить про условия обеспечения эффективности параллелизма. И тут я выделяю два условия.</p> <ol> <li> <p><em>Основное время уходит на полезную работу.</em> Тут мы сводим к минимуму программные блокировки и ожидания результатов при вызове внешних компонентов. Избавляемся от необходимости в синхронизации потоков, минимизируем количество IPC, оптимизируем запросы к БД и т.п. Пожалуй, именно с выполнения этого условия и нужно начинать процесс повышения эффективности параллелизма.</p> </li> <li> <p><em><a href="https://en.wikipedia.org/wiki/Big_O_notation" rel="external nofollow noopener" target="_blank">Вычислительная сложность</a> обработки одинакова для всех событий.</em> В самом деле, выполнение этого условия дает шансы на то, что время обработки каждого события будет плюс-минус одинаковое. Это значит, что простои обработчиков будут сведены к минимуму, поскольку они будут начинать и закачивать работу примерно в одно и тоже время.</p> </li> </ol> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       ┌─&gt; AAA ─┐
fork &gt;─┼─&gt; BBB ─┼─&gt; join
       └─&gt; CCC ─┘
</code></pre></div></div> <p>Если же вычислительная сложность разнится, то и время обработки каждого события будет разниться, провоцируя простой самых быстрых обработчиков в группе.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       ┌─&gt; AAAAAAAAA ─┐
fork &gt;─┼─&gt; BBBBB.... ─┼─&gt; join
       └─&gt; CCC...... ─┘
</code></pre></div></div> <p>Ниже я рассмотрю как эта теория соотносится с <a href="/blog/2024/log-and-queue-based-brokers/">Log-based- и Queue-based-брокерами</a>, что может повлиять на выбор брокера или на пересмотр сценариев по работе с ними.</p> <h3 id="распараллеливание-вычислений-в-log-based-брокерах">Распараллеливание вычислений в Log-based-брокерах</h3> <p>В контексте распараллеливания вычислений я выделяю две важных особенности Log-based-брокеров:</p> <ol> <li> <p><em>Уровень параллелизма зависит от количества партиций.</em> Мы не можем создать обработчиков больше, чем количество партиций.</p> </li> <li> <p><em>Неравномерная загрузка обработчиков, если время обработки сильно варьируется.</em> В разные партиции могут попасть сообщения с разной вычислительной сложностью.</p> </li> </ol> <p>Первая проблема с нехваткой обработчиков решается двумя способами, которые можно использовать совместно:</p> <ol> <li> <p><em>Увеличение числа партиций</em> (сразу много или добавляем по мере возрастания нагрузки). Существует ряд недостатков данного решения, в том числе дополнительные <a href="https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster" rel="external nofollow noopener" target="_blank">накладные расходы</a> на обслуживание партиций; увеличение времени балансировки; значительные сложности при сокращении числа партиций.</p> </li> <li> <p>Параллельная обработка пачки сообщений в разных потоках одного процесса ОС. Иначе говоря, потребитель считывает N-сообщений и каждое обрабатывает в отдельном потоке. Когда заканчивается обработка всех N-сообщений, происходит смещение к следующей пачке. Недостатки - необходимость ожидания окончания обработки всей пачки сообщений. Подход подробно описан <a href="https://www.uber.com/en-SE/blog/kafka-async-queuing-with-consumer-proxy/" rel="external nofollow noopener" target="_blank">тут</a>, имеет <a href="https://github.com/confluentinc/parallel-consumer" rel="external nofollow noopener" target="_blank">готовую реализацию</a>. Более глобально эту проблему пытаются решить на уровне Apache Kafka в рамках <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-932%253A%20Queues%20for%20Kafka" rel="external nofollow noopener" target="_blank">KIP-932</a>.</p> </li> </ol> <p>Вторая проблема куда более значительная для Log-based-брокеров, поскольку <em>по замыслу они не предназначены для нагрузки подобного рода</em>. Если от сообщения к сообщению время обработки варьируется существенно, то это может привести к <em>ребалансировке</em>. Один из потребителей может уйти в долгую обработку, перестав подавать признаки жизни, в результате чего брокер может счесть потребителя нерабочим и начать процесс перераспределения партиций. Это сложный и долгий процесс, который частично или полностью останавливает обработку событий топика.</p> <p>В случае с Apache Kafka решить проблему можно “на глазок”: установить более точные настройки для <a href="https://kafka.apache.org/documentation/#consumerconfigs_max.poll.records" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">max.poll.records</code></a> (сделать <em>поменьше</em>) и/или <a href="https://kafka.apache.org/documentation/#consumerconfigs_max.poll.interval.ms" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">max.poll.interval.ms</code></a> (сделать <em>побольше</em>). Или усложнить логику взаимодействия с брокером так, чтобы потребитель подавал брокеру признаки жизни, даже в случае долгой/зависшей обработки (см. методы <code class="language-plaintext highlighter-rouge">pause</code>/<code class="language-plaintext highlighter-rouge">resume</code>).</p> <p>Иногда эту проблему удается решить частично с помощью приёма “Типизация событий” (см. выше). Например, предположим, что событием является запрос на формирование сложного финансового отчета. Если пользователь укажет слишком большой календарный период, придется анализировать слишком много данных, это увеличит время формирования отчета. Если пользователь задаст более точный фильтр, это ожидаемо сократит время обработки. Таким образом, на стороне отправителя можно сделать небольшую эвристику - типизацию отчётов, например, на “простые” (“быстрые”) и “сложные” (“медленные”). Для каждого типа завести свой тип и топик. Обработчик каждого типа будет обслуживать очередь в своем темпе, со своими настройками.</p> <h3 id="распараллеливание-вычислений-в-queue-based-брокерах">Распараллеливание вычислений в Queue-based-брокерах</h3> <p>Пожалуй, тут я начну с совета:</p> <blockquote> <p>Для увеличения параллелизма МОЖНО отказаться от Log-based-брокера в пользу Queue-based, ЕСЛИ не важен порядок обработки событий, И ЕСЛИ не нужен лог событий.</p> </blockquote> <p>Этот совет особенно ценен в случае, когда <em>время обработки событий сильно варьируется</em>, поскольку это та нагрузка, к которой Queue-based-брокеры <em>особенно хорошо приспособлены</em>. Как только обработчик заканчивает обработку очередного сообщения, брокер передает ему новое. Обработчики работают non-stop, исключая простои, увеличивая пропускную способность и по-максимуму утилизируя выделенные ресурсы.</p> <p>Можно сделать мини-вывод, что Queue-based-брокеры отлично подходят:</p> <ul> <li>для задач с малопредсказуемой продолжительностью выполнения;</li> <li>когда гораздо важней как можно быстрей выполнить весь объем задач.</li> </ul> <p>Примеры идеальных задач для Queue-based-брокеров:</p> <ul> <li>задача формирование отчета по запросу-фильтру пользователя;</li> <li>поиск и анализ ссылок в документе;</li> <li>сборка мусора - удаление ненужных данных и т.п.</li> </ul> <p>В свою очередь Log-based-брокеры хорошо подходят для потоковой обработки событий, когда важен порядок следования и обработки, нужен лог событий и возможность запуска повторной обработки.</p> <h2 id="приём-5-локальность-данных">Приём №5: Локальность данных</h2> <p>Пожалуй, это один из основных принципов обработки данных в распределенных системах. Самое простое определение звучит так: <em>держите данные ближе к месту их обработки</em>. Этот приём направлен на оптимизацию вычислений, чтобы основное время уходило на полезную работу. Такой подход особенно оправдан при частом и одновременном обращении к некоторой части данных.</p> <p>Я предлагаю присмотреться к частному случаю этого принципа, т.к. обычно он более прост в реализации и, как правило, накладывает меньше <em>архитектурных ограничений</em>.</p> <blockquote> <p>Данные ДОЛЖНЫ находиться в месте их использования, ЕСЛИ они изменяются редко.</p> </blockquote> <p>Существует множество способов реализации этого приёма, выбор зависит от решаемой задачи, доступного времени и средств. Примеры реализации:</p> <ul> <li> <p><em>Локальный (файловый) кэш/индекс редко меняющихся данных.</em> Сюда же можно отнести алгоритм “Hash Join”. В большинстве случаев значительно ускоряет обработку, но требует усилий по поддержанию кэша/индекса в актуальном состоянии.</p> </li> <li> <p><em>Использование общей области памяти (shared memory) или общего диска.</em> Также значительно ускоряет обработку, но в какой-то степени увеличивает связность между взаимодействующими компонентами, добавляет зависимость от технологии взаимодействия. “Читатель” знает, куда, что и как пишет “писатель”, и наоборот. Помимо этого, взаимодействующие компоненты могут не ужиться на одной машине (разные требования к окружению, ресурсам, масштабированию и т.п.); общий диск может оказаться сетевым, что еще хуже скажется на производительности.</p> </li> </ul> <p>Теперь про жесткие архитектурные ограничения. Если рассматривать принцип локальности данных (data locality) в целом, способ его реализации может существенным образом повлиять на всё решение. Поэтому важно проанализировать все достоинства и недостатки каждого варианта. В качестве иллюстрации можно рассмотреть следующие примеры.</p> <ul> <li> <p><em>Модель хранения данных</em> - это тоже способ локализации данных. Например, key-value, column-family, индексы, да даже файловая система. Мы выбираем ту модель, которая наиболее удобна для большинства сценариев приложения. И я думаю, что многие сталкивались с ситуацией, когда модель хранения не отвечает существующим требованиям. Это способствует появлению неуклюжей и запутанной логики в коде.</p> </li> <li> <p><em>Использование денормализации данных или даже документно-ориентированных хранилищ</em> (например, MongoDB). Если необходимые данные распределены по множеству таблиц, потребуются достаточные усилия, чтобы собрать их вместе. Это создаст нагрузку на дисковую и сетевую инфраструктуру, увеличит время обработки. С другой стороны, мы получим избыточность данных и, если мы будем использовать только малую часть большого документа, это может негативно отразиться на сценариях чтения и записи.</p> </li> <li> <p><em>Использование локальной файловой системы для генерации отчета</em> вместо того, чтобы генерировать его в оперативной памяти или сразу производить запись в BLOB-хранилище. Преимущества очевидны - минимальное потребление памяти, сокращение количества сетевых обращений. Недостатки - места на локальном диске может не хватить; приложение должно позаботиться об удалении временных файлов.</p> </li> <li> <p><em>Алгоритм “Partitioned Hash Join”</em> - партиционирование разных потоков данных по одному ключу, чтобы иметь возможность эффективно объединять потоки на стороне обработчика. Этот подход применим только в случае, когда партиции могут быть помещены в оперативную память.</p> </li> </ul> <p>Подводя итог, скажу, что локализация данных (data locality) позволяет добиться значительных или даже прорывных успехов в сокращении времени обработки. Это очень сильный приём, но в этом же кроется и его слабость, т.к. за мощную оптимизацию приходится платить. И если на сегодняшний день эта цена может показаться не такой большой, то завтра, когда поменяются требования к системе, это может стать серьезным препятствием, чтобы двигаться дальше.</p> <h2 id="заключение">Заключение</h2> <p>Рассмотренные приёмы позволяют достаточно быстро добиться значительного ускорения потоков данных приложения. Не обязательно применять все, их можно использовать выборочно, оценив свои возможности и риски. Как минимум, можно подвергнуть свое решение критическому анализу и рассмотреть потоки данных приложения через призму предложенных подходов.</p> </div> </article> <br> <br> <div class="card"> <div class="card-body"> <h4 class="card-title">Понравилась статья?</h4> <p class="card-text"> Посмею напомнить, что у меня есть Telegram-канал <a href="https://t.me/arch_and_dev/79" rel="external nofollow noopener" target="_blank">Архитектоника в ИТ</a>, где я публикую материал на похожие темы примерно раз в неделю. Подписчики меня мотивируют, но ещё больше мотивируют живые дискуссии, ведь именно в них рождается истина. Поэтому подписывайтесь на канал и будем оставаться на связи! ;-) </p> <p class="card-text">Статьи из той же категории:</p> <ul class="list-disc pl-8"> <li class="my-2"> <p class="card-text"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/oom-killer/">OOM Killer к нам приходит</a> </p> </li> <li class="my-2"> <p class="card-text"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/throttling-and-cpu-usage/">Throttling - бесполезная трата CPU</a> </p> </li> <li class="my-2"> <p class="card-text"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/2025-year-summary/">Итоги 2025 года</a> </p> </li> <li class="my-2"> <p class="card-text"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/search-for-medical-documents/">Первичный анализ задачи поиска медицинских документов</a> </p> </li> <li class="my-2"> <p class="card-text"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/ontico-conf-transformation/">Трансформация конференций</a> </p> </li> </ul> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Александр Межов. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Напечатайте что-нибудь для поиска"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>