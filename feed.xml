<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ru"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://alexmas.github.io//feed.xml" rel="self" type="application/atom+xml"/><link href="https://alexmas.github.io//" rel="alternate" type="text/html" hreflang="ru"/><updated>2025-12-24T09:45:18+00:00</updated><id>https://alexmas.github.io//feed.xml</id><title type="html">blank</title><subtitle>Персональный сайт Александра Межова. </subtitle><entry><title type="html">Первичный анализ задачи поиска медицинских документов</title><link href="https://alexmas.github.io//blog/2025/search-for-medical-documents/" rel="alternate" type="text/html" title="Первичный анализ задачи поиска медицинских документов"/><published>2025-12-24T00:00:00+00:00</published><updated>2025-12-24T00:00:00+00:00</updated><id>https://alexmas.github.io//blog/2025/search-for-medical-documents</id><content type="html" xml:base="https://alexmas.github.io//blog/2025/search-for-medical-documents/"><![CDATA[<p>Сегодня предлагаю рассмотреть вполне конкретную задачу из реального проекта. Думаю, что подобный кейс достаточно интересен и его можно рассматривать для прокачки своих навыков по System Design.</p> <p><img src="/assets/img/blog/2025/2025-12-25-search-service.jpg" alt=""/></p> <p>Сразу скажу, что мы ещё не полностью решили описанную ниже задачу. Представленное решение — лишь один из возможных вариантов, черновик, который ещё не проверен на практике. Однако, выполнив достаточно подробный анализ, я решил поделиться им с вами, а не оставлять пылиться результаты проделанной работы в столе. В статье постарался адаптировать материал, чтобы он был понятен широкому кругу читателей и не требовал глубокого погружения в предметную область. Надеюсь, у меня получилось, и желаю вам приятного чтения.</p> <h2 id="задача">Задача</h2> <p>Необходимо реализовать быстрый поиск по метаданным медицинских документов.</p> <p>Грубо говоря, метаданные описывают содержимое документов с помощью набора атрибутов, которые можно поделить на три категории:</p> <ul> <li>общие атрибуты;</li> <li>атрибуты, характерные для типа документа;</li> <li>атрибуты, описывающие связи с другими документами.</li> </ul> <p>Небольшая часть атрибутов присутствует у всех документов, например, “ID пациента”, “дата создания”, “тип документа”, “состояние” и т.д. Однако документы бывают разных типов, соответственно, атрибутивный состав метаданных разных типов документов — разный. Например, состав атрибутов для “Осмотра терапевта” отличается от “Осмотра кардиолога”. Описание семантических связей между документами также является частью метаописания. Например, “Направление на анализы” может содержать ссылки на результаты (и наоборот).</p> <p>Типы данных атрибутов — скаляры (в основном целые числа разной разрядности, строки) и списки скаляров. Атрибутивный состав может меняться динамически, во время работы системы, без необходимости её повторного развертывания.</p> <p>Поиск документов сводится к их фильтрации по атрибутам. Условие фильтрации может быть сложным логическим выражением — произвольной комбинацией операторов <code class="language-plaintext highlighter-rouge">OR</code>/<code class="language-plaintext highlighter-rouge">AND</code>/<code class="language-plaintext highlighter-rouge">NOT</code>. Поиск по связанным документам не производится, но может производиться проверка наличия связей.</p> <p>Поисковые запросы можно поделить на две категории:</p> <ul> <li><em>Поиск по пациенту</em> — это поиск внутри электронной медицинской карты пациента, фильтрация документов определенного пациента — подавляющая часть запросов. Например: “найти все обращения пациента к кардиологу”.</li> <li><em>Популяционный поиск</em> — это фильтрация документов без указания пациента — малая часть запросов. Например, “найти документы, подписанные выбранным врачом”; “найти все больничные листы, выданные указанной поликлиникой за прошедший месяц”.</li> </ul> <p><img src="/assets/img/blog/2025/2025-12-25-search-service-01.png" alt=""/></p> <p>Важно, что подавляющая часть поисковых запросов идёт без указания периода создания документов. Иначе говоря, практически никогда не бывает запросов вида: “найди документы, созданные за последний год”, “за последний месяц” и т.п.</p> <p>По умолчанию результат поиска должен быть отсортирован по дате создания документов в обратном хронологическом порядке (от новых документов к старым).</p> <p>Документы могут изменяться несколько раз подряд. Нужно, чтобы поиск возвращал релевантные данные, игнорируя старые версии документов.</p> <p>В идеале решение должно предполагать возможность постраничной выборки.</p> <h3 id="уточнение-требований">Уточнение требований</h3> <p>Разрабатываемая медицинская система уже имеет функцию поиска. Она реализована на базе SQL-хранилища, выполняет все функциональные требования, но работает крайне медленно. Поисковый запрос трансформируется в SQL-запрос, который представляет собой оператор <code class="language-plaintext highlighter-rouge">SELECT</code> с множественными <code class="language-plaintext highlighter-rouge">INNER JOIN</code> и операциями фильтрации, которые соответствуют переданному запросу.</p> <p>Существующее решение таково, что поиск осуществляется по операционному хранилищу, следовательно, документ доступен для поиска сразу после сохранения. Возможно, что некоторые пользователи сервиса рассчитывают на это поведение, поэтому целевое решение должно стремиться к минимальной задержке между моментом, когда данные были изменены и когда они стали доступны для поиска.</p> <p><img src="/assets/img/blog/2025/2025-12-25-search-service-02.png" alt=""/></p> <p>Система существует долгие годы, и так сложилось, что некоторые смежные продукты, обнаружив <a href="/blog/2025/optimistic-architecture/">чрезмерную гибкость API</a> сервиса поиска, стали отправлять популяционные запросы. Однако в общем случае популяционный поиск не является задачей медицинской системы, т.к. для её эффективного решения нужно строить <em>витрины данных</em>, а вид витрин сильно зависит от специфических потребностей отдельно взятого продукта. Следовательно, смежные продукты должны самостоятельно организовывать необходимые им витрины данных, а медицинская система, в свою очередь, обязана лишь предоставлять механизм, необходимый для организации таких пользовательских витрин. Например, система может публиковать асинхронные уведомления об изменениях документов.</p> <p>Таким образом, принято стратегическое архитектурное решение, что смежные продукты будут постепенно отказываться от популяционных запросов, организуя собственные витрины данных. Соответственно, нужно идентифицировать всех таких пользователей, уведомить их о необходимости доработок и обговорить сроки реализации.</p> <p><img src="/assets/img/blog/2025/2025-12-25-search-service-03.png" alt=""/></p> <p>Между тем, популяционный поиск существует, поэтому искомое решение должно учитывать этот сценарий и обеспечивать его должную производительность.</p> <h3 id="нефункциональные-требования">Нефункциональные требования</h3> <p>Текущая база данных такова:</p> <ul> <li>Количество пациентов: <code class="language-plaintext highlighter-rouge">25 000 000</code></li> <li>Количество документов: <code class="language-plaintext highlighter-rouge">5 000 000 000</code></li> <li>Количество общих атрибутов: до <code class="language-plaintext highlighter-rouge">20</code></li> <li>Количество дополнительных атрибутов: до <code class="language-plaintext highlighter-rouge">50</code> (чаще до <code class="language-plaintext highlighter-rouge">5</code>)</li> <li>Количество связей: до <code class="language-plaintext highlighter-rouge">100</code> (чаще до <code class="language-plaintext highlighter-rouge">2</code>)</li> </ul> <p>Динамика прироста базы данных:</p> <ul> <li>Прирост населения в год: <code class="language-plaintext highlighter-rouge">120 000</code></li> <li>Прирост документов в день: <code class="language-plaintext highlighter-rouge">5 000 000</code></li> <li>Количество лет для прогноза: <code class="language-plaintext highlighter-rouge">10</code></li> </ul> <p>Показатели производительности:</p> <ul> <li>Показатель нагрузки: <code class="language-plaintext highlighter-rouge">1000</code> RPS.</li> <li>Время поиска по пациенту: ≤ <code class="language-plaintext highlighter-rouge">200</code> ms (P99).</li> <li>Время популяционного поиска: ≤ <code class="language-plaintext highlighter-rouge">1000</code> ms (P99).</li> <li>Лимит на количество строк в результате поиска: <code class="language-plaintext highlighter-rouge">2000</code></li> <li>Задержка сохранил/нашёл: ≤ <code class="language-plaintext highlighter-rouge">1000</code> ms</li> </ul> <h2 id="анализ-условий">Анализ условий</h2> <p>Сделаем декомпозицию и анализ исходных условий. Большая часть анализа сконцентрирована на проработке требований к хранилищу данных, организации хранения и методам поиска.</p> <p>Прежде всего нужно выделить основные архитектурные свойства сервиса поиска:</p> <ul> <li><em>Доступность.</em> Поиск медицинских данных — это ключевая часть медицинской системы. Если она будет недоступна, то многие сценарии работы будут парализованы. Хранилище, которое будет выбрано для организации поискового индекса, должно обладать хорошей доступностью.</li> <li><em>Производительность.</em> Как следует из условий, производительность поиска важна, но не критична. Тем не менее, рассматриваемая задача решается в первую очередь из-за проблем с производительностью. Особое внимание следует уделить быстродействию выполнения запросов.</li> <li><em>Масштабируемость и адаптивность.</em> База данных активно растёт, количество пользователей растёт, уровень цифровизации увеличивается. Необходимо, чтобы система могла адаптироваться ко всё растущим потребностям. База данных и используемые подходы к хранению должны соответствовать данному требованию.</li> </ul> <blockquote> <p>Далее часто будет использоваться термин <em>поисковый индекс</em>. Будем считать, что это структуры данных поискового хранилища, которые позволяют осуществлять быстрый поиск. Поисковый индекс может быть реализован по-разному — это может быть одна или несколько таблиц в базе данных, бинарный индекс, префиксный индекс и т.п. Главная его задача — ускорение поиска.</p> </blockquote> <h3 id="общие-требования">Общие требования</h3> <p>Решаемая задача — это не поиск, а <strong>фильтрация данных</strong>. Поиск — достаточно многозначный термин, который предполагает некоторую нечёткость в запросе. Например, “поиск по ключевым словам”, “поиск по фразе”, “поиск по смыслу”. В текущем контексте мы решаем задачу фильтрации данных, которая не допускает вариативности в толковании условий запроса или нечёткости результатов его выполнения.</p> <p>Например, если среди всех документов выбранного пациента есть только 2 осмотра терапевта, а в поисковом запросе указано, что нужно вернуть документы с типом “Осмотр терапевта”, то результатом выполнения такого запроса ожидаемо должен быть набор из этих 2 документов. Соответственно, результат не предполагает, что в ответе вернутся все документы, в которых встречается <em>фраза</em> “Осмотр терапевта” или что-то в этом роде.</p> <p>Таким образом, решение не подразумевает нечёткий поиск, например, полнотекстовый поиск, поиск похожих значений и т.п. Напротив, нужно решить задачу чёткого поиска, фильтрации данных. Следовательно, <strong>выбираемые инструменты должны в первую очередь эффективно решать задачу фильтрации данных</strong>.</p> <h3 id="особенности-запроса">Особенности запроса</h3> <p>По условию фильтр — сложное логическое выражение с произвольной комбинацией операторов <code class="language-plaintext highlighter-rouge">OR</code>/<code class="language-plaintext highlighter-rouge">AND</code>/<code class="language-plaintext highlighter-rouge">NOT</code>. Подобные запросы типичны для <strong>OLAP-хранилищ</strong> и совершенно нетипичны, например, для OLTP и полнотекстовых индексов.</p> <p>Возможная вариативность атрибутов в условии фильтрации полностью исключает возможность использования реляционных СУБД, т.к. ни одна реляционная база не выдержит создания огромного количества индексов на каждый искомый атрибут. Без индексов поиск будет работать, но медленно, неэффективно, с большой утилизацией CPU и I/O. Именно этот результат демонстрирует существующее решение на базе SQL-хранилища.</p> <p>С другой стороны, вариативность атрибутов в условии фильтрации — <strong>характерная нагрузка для колоночных баз данных</strong>, например, ClickHouse или Apache Druid. Именно поэтому многие OLAP-хранилища — это колоночные базы данных.</p> <p>Например, в ClickHouse атрибуты (колонки) хранятся в отдельных файлах данных, что положительно сказывается на эффективности выполнения запросов. Если в условии фильтрации фигурируют только 2 атрибута, то и считываться с диска будут данные только из 2 файлов. Это значительно эффективней, т.к. считываются именно те данные, которые нужны для поиска. Такой подход существенно отличает колоночные базы от строковых, в которых данные хранятся построчно, и при вычитывании строк вычитывается множество ненужных данных: все колонки строки, а также соседние строки, ведь файлы данных читаются с диска блоками фиксированных размеров. Подобное поведение колоночных баз <strong>существенно снижает нагрузку на I/O</strong>.</p> <p>Дополнительно, колоночное хранение позволяет <strong>существенно сжимать данные</strong> (в среднем до 10-20 раз, в зависимости от вариативности значений в атрибутах), следовательно, <strong>экономить на хранении</strong>. Сжатие данных предполагает не только компрессию, но и удаление повторяющихся значений. Благодаря этому размеры колоночных файлов становятся незначительными, что <strong>приводит к кратному ускорению поиска</strong>, снижая нагрузку на I/O.</p> <p>Наконец, в колоночных базах для каждой колонки может строиться вероятностный индекс (например, Bloom- или <a href="/blog/2025/data-migration-and-hll/">HLL-фильтр</a>). Этот индекс формируется на основе вставляемых данных. Используя его, можно практически моментально узнать, есть ли в файле искомое значение. Это избавляет от бессмысленного сканирования файлов данных, снижая нагрузку на I/O.</p> <p><img src="/assets/img/blog/2025/2025-12-25-search-service-04.png" alt=""/></p> <h3 id="особенности-хранения">Особенности хранения</h3> <p>По условию задачи большинство, если не все, поисковые запросы идут без указания периода создания документов, что могло бы ограничивать объем обрабатываемых данных. Без подобной фильтрации поиск неявно предполагает <strong>сканирование всей базы данных за все периоды</strong>. В такой постановке <strong>время поиска будет расти вместе с ростом базы</strong>. Естественно, такое решение недопустимо, время поиска не должно зависеть от размера базы, и нужно найти подход, который ограничит выборку данных даже при отсутствии в пользовательском запросе фильтра по дате создания документов.</p> <p>Для выполнения поставленной задачи напрашивается какое-то разбиение всего множества данных на группы фиксированных размеров (партиции), но так, чтобы при выполнении запросов можно было выбирать не все, а только определённые партиции. Такой подход, как минимум, обеспечит независимость времени поиска от размера базы и, вероятно, благоприятно скажется на скорости поиска. Однако, чтобы понять, как именно сделать партиционирование данных, нужно рассмотреть и принять к сведению нижеследующие факты.</p> <ul> <li>Поток сохраняемых документов условно бесконечный. Количество пациентов ограничено, но есть риск неравномерного распределения данных по разным группам пациентов.</li> <li>Результат поиска должен быть отсортирован по дате создания документов. Разумно, если документы сразу будут храниться в сортированном виде, чтобы не сортировать данные при каждой выборке.</li> </ul> <p>По совокупности напрашивается единственно верный вывод: <strong>документы в основной таблице поискового хранилища должны храниться с партиционированием по времени создания и с предварительной сортировкой по времени создания</strong> (в обратном хронологическом порядке — от новых документов к старым, как требуется по условию).</p> <p>Подобный подход обеспечит <strong>равномерное распределение данных по всем партициям</strong>, что неминуемо ограничит и усреднит максимальное время фильтрации по каждой партиции. Более того, такое распределение может производиться в автоматическом режиме, без необходимости ручной настройки диапазонов (например, при партиционировании по пациентам возник бы вопрос о количестве партиций). Гранулярность партиционирования (по годам, месяцам, неделям и т.п.) концептуально не важна, но будет рассчитана позже.</p> <p><img src="/assets/img/blog/2025/2025-12-25-search-service-05.png" alt=""/></p> <p>Партиционирование по дате создания в том числе позволяет решить вопрос с автоматическим ограничением объема обрабатываемых данных. Для каждого пациента нужно хранить сведения, за какие периоды по нему есть документы. Например, в виде <a href="/blog/2025/data-seive/">вспомогательной таблицы</a> “пациент — список дат” или “пациент — минимальная дата — максимальная дата”. Окончательный вид этой таблицы следует определить на этапе реализации. Вспомогательную таблицу можно заполнять во время записи в поисковый индекс, а затем использовать во время поиска в качестве “ускорителя”. Такой подход можно организовать без дополнительного программирования, путём создания материализованного представления (materialized view), которое будет строиться на базе основной таблицы поискового индекса. Сервис поиска будет писать только в основную таблицу, а база данных будет автоматически формировать и обеспечивать консистентное представление вспомогательной таблицы. Материализованные представления поддерживают все известные OLAP-хранилища. В крайнем случае вспомогательную таблицу можно формировать и вручную, в коде приложения.</p> <p><img src="/assets/img/blog/2025/2025-12-25-search-service-06.png" alt=""/></p> <h3 id="актуализация-поискового-индекса">Актуализация поискового индекса</h3> <p>Документы могут изменяться, следовательно, поисковый индекс может устаревать, т.е. хранить старые версии документов. В существующем решении на базе SQL-хранилища такого не происходит, т.к. поиск осуществляется по операционным данным (данные сохраняются в те же таблицы, по которым осуществляется поиск). Очевидно, что новое решение должно, во-первых, <strong>минимизировать время индексации</strong> — новые данные должны появляться в индексе как можно быстрей; во-вторых, <strong>удалять из индекса старые версии документов</strong>, чтобы вероятность их появления в результатах поиска была минимальна, и они не занимали место на диске.</p> <p>Для любой БД удаление — это тяжёлая операция. Это вполне объяснимо: хранилища данных проектируются для хранения данных, а не для их удаления. Удалять данные вручную — это вдвойне неблагодарная работа, т.к. механики эффективного удаления данных очень сильно зависят от внутренних особенностей реализации используемого хранилища. Будет отлично, если хранилище поискового индекса предоставляет механизм автоматического удаления старых версий документов. В противном случае нужно будет реализовать механизм асинхронной очистки, а это крайне непростая задача.</p> <p>К сожалению, не все базы данных имеют средства автоматического схлопывания строк. Из известных мне только ClickHouse имеет подобную функциональность, которая реализуется в виде стратегий <a href="https://clickhouse.com/docs/engines/table-engines/mergetree-family/collapsingmergetree"><code class="language-plaintext highlighter-rouge">CollapsingMergeTree</code></a> и <a href="https://clickhouse.com/docs/ru/engines/table-engines/mergetree-family/versionedcollapsingmergetree"><code class="language-plaintext highlighter-rouge">VersionedCollapsingMergeTree</code></a>.</p> <h3 id="популяционные-запросы">Популяционные запросы</h3> <p>Популяционный поиск предполагает наличие <strong>витрин данных</strong>. В противном случае любой популяционный поиск по “сырым данным” будет медленным, ведь <strong>время поиска будет зависеть от размера базы</strong>, а это абсолютно неприемлемо.</p> <p>Строить витрины данных или их подобие вручную, в коде приложения, непозволительно дорого и долго. Нужно рассматривать такие решения, которые будут предлагать максимальную адаптивность к новым или существующим популяционным запросам. Это значит, что <strong>используемое хранилище должно предоставлять средства автоматического создания витрин данных</strong> — срезов данных, которые будут ускорять выполнение запросов определённого типа. Самый простой способ организации таких “ускорителей” — это материализованные представления, работающие по принципу, который описан выше, в примере автоматического ограничения выборки при поиске по пациенту.</p> <p>Сначала сервис поиска анализирует запрос и выбирает нужную стратегию поиска. Реализация стратегии знает, какие оптимизации и с помощью каких именно таблиц, можно применить для ускорения входящего запроса.</p> <p><img src="/assets/img/blog/2025/2025-12-25-search-service-07.png" alt=""/></p> <h3 id="задержка-индексации">Задержка индексации</h3> <p>Раздельное хранение операционных и аналитических данных решает вопрос быстродействия, но создаёт проблему с запаздыванием данных в поисковом индексе. Сначала метаданные документов будут сохраняться в операционное хранилище, а затем реплицироваться в индексное. В итоге возникает временной зазор, когда документ уже сохранён, но всё ещё недоступен для поиска. Для минимизации задержки следует рассматривать базы данных, адаптированные для быстрой записи (write-heavy workload).</p> <p>На следующем рисунке показана ситуация, когда один пользователь изменил документ, а второй не смог его найти или результаты поиска уже устарели.</p> <p><img src="/assets/img/blog/2025/2025-12-25-search-service-08.png" alt=""/></p> <p>Дополнительно нужно проверить, насколько критично подобное нарушение изоляции для существующих сценариев и интеграций. Вполне возможно, что для некоторых случаев придётся добавлять синхронное ожидание окончания индексации.</p> <p>Вообще говоря, трудно найти сценарии, когда только что сохранённая медицинская информация должна понадобится моментально, и неточность поиска в рамках небольшого лага индексации окажет непоправимый вред пациенту. Как отмечалось выше, гораздо важней <em>доступность</em> функции поиска, поэтому нужно пойти на оправданный компромисс и принять стратегическое архитектурное решение отказа от необходимости синхронного ожидания окончания индексации. Сценарии, в которых важно реагировать на изменения документов, должны быть переделаны на асинхронный режим работы с помощью подписки на уведомления об изменениях документов (см. выше).</p> <h3 id="размер-индекса">Размер индекса</h3> <p>Можно сделать примерную оценку размера индекса. Для этого нужно составить таблицу из атрибутов документа, их размера и предполагаемой степени сжатия (в зависимости от характера данных).</p> <p>Например, идентификатор документа имеет тип данных <a href="/blog/2025/selecting-b-tree-and-uuids/">UUID</a>, занимает 16 байт и имеет низкую степень сжатия в районе 1, т.к. <code class="language-plaintext highlighter-rouge">UUID</code> имеет высокую вариативность. Дата создания документа имеет тип данных <code class="language-plaintext highlighter-rouge">DateTime</code>, занимает 8 байт и имеет высокую степень сжатия в районе 5, т.к. документы упорядочены по дате создания.</p> <p>Предполагаемую степень сжатия лучше оценить заранее, выполнив ряд тестов, или посмотреть на аналитические рекомендации к той БД или алгоритму, который собираетесь использовать. Например, в документации ClickHouse можно найти <a href="https://clickhouse.com/docs/data-compression/compression-in-clickhouse">статью</a>, в которой даются примерные оценки сжатия данных.</p> <p>Просуммировав полученные значения, можно получить два показателя: размер сырых данных и предполагаемый размер сжатых данных.</p> <p>Допустим, анализ показал, что сырые данные одного документа будут занимать <code class="language-plaintext highlighter-rouge">1.5 Kb</code>, а сжатые — <code class="language-plaintext highlighter-rouge">0.5 Kb</code>. Умножив эти показатели на общее количество документов (указанное в условии задачи), можно вычислить предполагаемый размер индекса.</p> <ul> <li>Сырые данные: <code class="language-plaintext highlighter-rouge">5000000000 * 1.5 Kb = 6.98 Tb</code></li> <li>Сжатые данные: <code class="language-plaintext highlighter-rouge">5000000000 * 0.5 Kb = 2.33 Tb</code></li> </ul> <p>При стабильном приросте 5 млн. документов в день в течение 10 лет в базу будет добавлено еще 18 млрд. документов. Соответственно, легко можно вычислить предполагаемый прирост.</p> <ul> <li>Сырые данные: <code class="language-plaintext highlighter-rouge">+25.15 Tb</code> (итого <code class="language-plaintext highlighter-rouge">32.13 Tb</code>)</li> <li>Сжатые данные: <code class="language-plaintext highlighter-rouge">+8.38 Tb</code> (итого <code class="language-plaintext highlighter-rouge">10.71 Tb</code>)</li> </ul> <p>При факторе репликации x3 получаем следующие значения (учитываются только сжатые данные).</p> <ul> <li>Текущие потребности: <code class="language-plaintext highlighter-rouge">2.33*3 = 6.98 Tb</code></li> <li>Потребности в перспективе 10 лет: <code class="language-plaintext highlighter-rouge">10.71*3 = 32.13 Tb</code></li> </ul> <h3 id="масштабирование-хранения">Масштабирование хранения</h3> <p>База данных непрерывно растёт, а сам рост имеет тенденцию к ускорению (за счёт активной цифровизации). Очевидно, что хранилище данных должно предполагать эффективные механизмы горизонтального масштабирования данных. В идеале оно должно быть простым и <strong>адаптивным</strong>, с минимальным вмешательством человека.</p> <p>Вполне возможно, что в будущем понадобится разделение хранилища на <em>горячее</em> и <em>холодное</em>. В холодное хранилище будут перетекать старые данные, т.к. очевидно, что любая медицинская информация со временем утрачивает свою значимость и актуальность. Предложенное выше партиционирование индекса по дате создания документов способствует эффективному решению этой проблемы.</p> <h3 id="контроль-целостности">Контроль целостности</h3> <p>Организация поискового индекса в отдельной базе данных предполагает необходимость начального наполнения этой базы, а также её последующей синхронизации с хранилищем оперативных данных. Учитывая, что существующее решение основано на базе SQL-хранилища, начальное наполнение нового поискового индекса можно сделать с помощью CDC-конвейера (Change Data Capture), выполненного с помощью <a href="https://debezium.io/">Debezium</a>.</p> <p>Как показывает практика, в распределённых системах всё может пойти не так, как задумано, поэтому нужно сразу предусмотреть способы оперативной заливки данных в поисковый индекс, его частичной или полной синхронизации с оперативным хранилищем, а также <strong>метрики обнаружения рассогласования и потери целостности</strong>. Этот контроль нужно производить асинхронно, анализируя результаты поиска.</p> <h2 id="требования-к-хранилищу">Требования к хранилищу</h2> <p>Подводя итоги, можно выделить следующие ключевые требования к хранилищу данных для построения поискового индекса:</p> <ul> <li>специализация на чётком поиске (фильтрации данных);</li> <li>специализация на OLAP с колоночным хранением данных;</li> <li>возможность партиционирования по времени;</li> <li>возможность создания материализованных представлений;</li> <li>возможность автоматического удаления старых версий;</li> <li>минимальная латентность при сохранении;</li> <li>поддержка сжатия данных;</li> <li>возможность горизонтального масштабирования;</li> <li>открытый исходный код;</li> <li>активная поддержка;</li> <li>доступная лицензия;</li> <li>условная бесплатность.</li> </ul> <p>Дополнительные требования, которые относятся к разряду желательных, но не обязательных:</p> <ul> <li>удобный язык запросов (желательно SQL-подобный);</li> <li>наличие опыта использования и поддержки.</li> </ul> <h2 id="выбор-хранилища">Выбор хранилища</h2> <p>По совокупности обстоятельств идеальным кандидатом для выбора является <a href="https://clickhouse.com/">ClickHouse</a>. Он отвечает всем предъявленным требованиям, включая удобный язык запросов (SQL).</p> <blockquote> <p><strong>Интересный факт</strong></p> <p>В рамках конференции HighLoad++ 2025 был доклад <a href="https://highload.ru/moscow/2025/abstracts/16516">“Как мы ускоряли поиск в модели EAV для 13500 атрибутов через ClickHouse”</a> (от МТС/MWS). Решалась схожая задача: у каждого документа большой и вариативный состав атрибутов, по которым производится аналитический поиск. Задача была эффективно решена с использованием ClickHouse и ряда понятных техник, которые также можно взять на вооружение. В рамках секции вопросов-ответов было подмечено, что <a href="https://druid.apache.org/">Apache Druid</a> решает данную задачу не менее эффективно, однако все согласились, что ClickHouse более известная и развитая технология.</p> </blockquote> <h2 id="план-реализации">План реализации</h2> <p>Примерный план реализации нового решения таков.</p> <ul> <li>Согласовать базовый вариант схемы данных поискового индекса.</li> <li>Сделать первоначальное наполнение индекса с помощью CDC-конвейера. При копировании данных важно следить за состоянием БД и инфраструктуры. Возможно, это даст подсказки относительно эффективности схемы данных; добавит понимание относительно задержек при записи.</li> <li>Провести нагрузочное тестирование, используя типовые поисковые запросы. До автоматического тестирования следует провести ручное тестирование выполнения типовых запросов. Как правило, этого вполне достаточно, чтобы найти основные огрехи схемы данных. Когда ручная проверка перестанет давать результаты, можно переходить к настоящему нагрузочному тестированию.</li> <li>Итеративно повторять предыдущие шаги, пока не будут достигнуты желаемые показатели по производительности, нагрузке на CPU, I/O.</li> <li>Последним шагом добавить поддержку нового поиска в код сервиса. При внедрении нового поиска желательно использовать канареечное развертывание с возможностью отката на предыдущий вариант поиска.</li> </ul> <h2 id="послесловие">Послесловие</h2> <p>Посмею напомнить, что это один из возможных вариантов решения задачи. Как и всегда, подобные решения должны проходить многократные стадии тестирования и апробации. Полное решение достаточно сложное, поэтому важно спланировать свою работу таким образом, чтобы как можно раньше убедиться в его перспективности.</p> <p>Не могу сказать, можно ли экстраполировать решение на другие предметные области. Например (фантазирую), вместо поиска по документам пациента делать поиск по товарам на складе. Однако хотелось бы понять, в каких ещё предметных областях подобное решение могло бы быть приемлемо. Если у вас есть опыт реализации подобных сервисов, не стесняйтесь, оставляйте обратную связь!</p>]]></content><author><name></name></author><category term="article"/><category term="arch"/><category term="db"/><summary type="html"><![CDATA[Сегодня предлагаю рассмотреть вполне конкретную задачу из реального проекта. Думаю, что подобный кейс достаточно интересен и его можно рассматривать для прокачки своих навыков по System Design.]]></summary></entry><entry><title type="html">Трансформация конференций</title><link href="https://alexmas.github.io//blog/2025/ontico-conf-transformation/" rel="alternate" type="text/html" title="Трансформация конференций"/><published>2025-12-16T00:00:00+00:00</published><updated>2025-12-16T00:00:00+00:00</updated><id>https://alexmas.github.io//blog/2025/ontico-conf-transformation</id><content type="html" xml:base="https://alexmas.github.io//blog/2025/ontico-conf-transformation/"><![CDATA[<p>Если кто-то пропустил, то в течение года нарастал хайп на тему того, что текущий формат конференций уже устарел. И вот накануне нового года Онтико сформулировало <a href="https://ontico.ru/manifest.html">концепцию</a> “конференций развития”, заявив об этом во всех своих <a href="https://t.me/HighLoadChannel/5108">каналах</a> и чатах.</p> <p><img src="/assets/img/blog/2025/2025-12-16-ontico-conf-transformation.jpg" alt=""/></p> <p>Честно говоря, концепция больше похожа на манифест, и можно только догадываться, какие именно трансформации произойдут. Между тем, очевиден вектор развития — практическая направленность и ориентация на текущие потребности аудитории. Пожалуй, в эпоху доступности информации это единственно правильное направление развития. Не рассчитываю, что ближайшие конференции сразу получатся такими, как заявлено, т.к. новый формат требует перестройки на всех уровнях (сознания), но очень надеюсь на итоговый успех.</p>]]></content><author><name></name></author><category term="post"/><category term="conf"/><summary type="html"><![CDATA[Если кто-то пропустил, то в течение года нарастал хайп на тему того, что текущий формат конференций уже устарел. И вот накануне нового года Онтико сформулировало концепцию “конференций развития”, заявив об этом во всех своих каналах и чатах.]]></summary></entry><entry><title type="html">9 архитектурных заблуждений о распределённых системах</title><link href="https://alexmas.github.io//blog/2025/9-fallacies-distributed-computing/" rel="alternate" type="text/html" title="9 архитектурных заблуждений о распределённых системах"/><published>2025-12-12T00:00:00+00:00</published><updated>2025-12-12T00:00:00+00:00</updated><id>https://alexmas.github.io//blog/2025/9-fallacies-distributed-computing</id><content type="html" xml:base="https://alexmas.github.io//blog/2025/9-fallacies-distributed-computing/"><![CDATA[<p>По сути, каждый, кто впервые создаёт распределённое приложение, делает следующие 8 предположений. Все они в конечном итоге оказываются ложными и все приводят к <em>большим</em> проблемам и <em>болезненному</em> опыту.</p> <p><img src="/assets/img/blog/2025/2025-12-12-9-fallacies-distributed-computing.jpg" alt=""/></p> <p>Это цитата, а сами <a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing">заблуждения</a> сформулированы более 30 лет назад (1991-1997) и до сих пор актуальны. Авторство приписывают Peter Deutsch и некоторым инженерам из Sun Microsystems.</p> <ol> <li> <p><em>The network is reliable / Сеть надёжна.</em> Думаем о том, как будет совершаться вызов или доставляться сообщение. Обеспечение надёжности передачи можно возложить на внешние механизмы (инфраструктуру, очереди, оркестраторы, outbox и т.п.); и/или самостоятельную реализацию (retries, dead letter, deadline propagation, circuit breakers и т.п.). На этом же уровне думаем о возможной многократной доставке, порядке и идемпотентности обработки.</p> </li> <li> <p><em>Latency is zero / Нулевая задержка.</em> Думаем, в какой сети происходит взаимодействие: в локальной или глобальной (через горы-моря-океаны). Задержка более проблематична, чем пропускная способность, ведь есть физические ограничения по скорости передачи. Соответственно, стараемся минимизировать количество сетевых взаимодействий; размер передаваемых данных; оптимизируем маршруты, необходимые для выполнения каждого сценария; вспоминаем про кэширование, пакетную обработку и <a href="/blog/2024/data-flow-speeding-up/">локальность вычислений</a>.</p> </li> <li> <p><em>Bandwidth is infinite / Неограниченная пропускная способность.</em> Пропускная способность растет, но растут и наши потребности. Вопрос лишь в том, насколько они адекватны. Насколько адекватно, когда сервис возвращает модель из множества атрибутов, но из всех нужен только один? Умножаем размер одного такого сообщения на их количество в секунду и сравниваем полученный результат с пропускной способностью используемой сети, принимая во внимание возможные сетевые потери. Только на оптимизации трафика можно существенно сэкономить и улучшить показатели. Тут можно вспомнить и про бинарные форматы (Avro, Protobuf, MessagePack).</p> </li> <li> <p><em>The network is secure / Сеть безопасна.</em> С одной стороны, уровень безопасности должен соответствовать уровню возможных угроз. С другой, для атаки всегда пытаются найти самое слабое звено. Поэтому в идеале защита не только по внешнему периметру, но и внутри. Как минимум, стоит задуматься об аутентификации/авторизации запросов, разделении аккаунтов доступа к используемым ресурсам (БД и т.п.). Для себя я нашел очень хорошую шпаргалку по этой теме — <a href="https://cheatsheetseries.owasp.org/">OWASP Cheat Sheet Series</a>.</p> </li> <li> <p><em>Topology doesn’t change / Топология не меняется.</em> После развертывания приложение уже не под вашим контролем. Считаем, что приложение развертывается в дикой и враждебной среде, где узлы появляются и исчезают в случайные моменты времени. Никогда не полагаемся на конкретные маршруты, узлы и IP-адреса; всё должно быть адаптивно. Изменение топологии не должно заставлять менять приложение.</p> </li> <li> <p><em>There is one administrator / Администратор всегда один.</em> Проблема проявляется сильней, если есть отдельная операционная команда или даже отдельная организация, которая выполняет эту роль. Налаживаем коммуникации, автоматизируем развертывание, добавляем средства диагностики и инструкции использования. Всё это работает в обе стороны: упрощаете жизнь операционной команде — упрощаете жизнь себе.</p> </li> <li> <p><em>Transport cost is zero / Передача данных бесплатна.</em> Сериализация/десериализация — это затраты на память и CPU; возможность передачи по сети — это затраты на оборудование и его обслуживание. Здесь архитектор и разработчик должны еще раз вернуться к заблуждениям 2 и 3.</p> </li> <li> <p><em>The network is homogeneous / Сеть однородна.</em> Даже в локальной сети однородность — редкое достижение. Разные производители и ресурсы, ОС и приложения, разные версии API и т.д. Выжить в этом безумном мире помогает стандартизация и обратная совместимость.</p> </li> </ol> <p>И 9-е бонусное заблуждение лично от меня:</p> <p><strong>9.</strong> <em>Контейнеры бесплатны.</em> Не хватает производительности — докинем еще несколько экземпляров! Выглядит разумно для “тушения пожаров”, но не в долгосрочной перспективе. Оптимизация кода или пересмотр решения — улучшают производительность; масштабирование — позволяет справиться с нагрузкой!</p> <hr/> <p>Думаю, что каждый увидел себя в каждом эпизоде! Но кто без греха?! Всем поменьше заблуждений!</p>]]></content><author><name></name></author><category term="post"/><category term="arch"/><summary type="html"><![CDATA[По сути, каждый, кто впервые создаёт распределённое приложение, делает следующие 8 предположений. Все они в конечном итоге оказываются ложными и все приводят к большим проблемам и болезненному опыту.]]></summary></entry><entry><title type="html">Порочные связи между компонентами</title><link href="https://alexmas.github.io//blog/2025/connascence/" rel="alternate" type="text/html" title="Порочные связи между компонентами"/><published>2025-12-03T00:00:00+00:00</published><updated>2025-12-03T00:00:00+00:00</updated><id>https://alexmas.github.io//blog/2025/connascence</id><content type="html" xml:base="https://alexmas.github.io//blog/2025/connascence/"><![CDATA[<p>Думаю, многие пытались оценивать качество своей архитектуры, анализируя входящие и исходящие связи между элементами. В этом контексте принято говорить о cohesion и coupling. А что насчёт качества связей?</p> <p><img src="/assets/img/blog/2025/2025-12-04-connascence.jpg" alt=""/></p> <p><a href="https://habr.com/ru/articles/894766/">Принцип каскадного снижения связанности</a>, предложенный Русланом Сафиным, контролирует баланс между cohesion и coupling на разных уровнях декомпозиции. Однако данный принцип, как и сами понятия cohesion и coupling, не отвечает на вопрос, насколько оправданы существующие связи, насколько они здоровы. Что если наличие связи между элементами не связывает их, а привязывает один к другому, сдерживая развитие обоих? Такие связи можно назвать обременительными, нездоровыми, порочными.</p> <p>Большую попытку категоризировать виды связей предпринял Meilir Page-Jones в своей книге “What Every Programmer Should Know About Object-Oriented Design” (1996), введя понятие <em>connascence</em> (от лат. “рождённые вместе”). В русскоязычной литературе можно встретить прямую транслитерацию — <em>коннасценция</em>, но я предпочитаю слово <em>взаимозависимость</em> (interdependence), т.к. сам автор сказал, что это точный синоним.</p> <blockquote> <p>Два элемента взаимозависимы, если для поддержания общей работоспособности они должны изменяться одновременно.</p> </blockquote> <p>Вместе с определением было предложено несколько <em>степеней взаимозависимости</em>, которые подразделяются на две группы: <em>статические</em> (в программном коде) и <em>динамические</em> (во время исполнения).</p> <blockquote> <p>Статические делятся по имени, типу, смыслу, порядку и алгоритму. Например, вызов метода и его определение (в классе) связаны по имени; функционально зависимые операторы связаны порядком; код клиента и сервера связан общим алгоритмом шифрования. Динамические делятся по порядку и времени выполнения, значению, ссылочной идентичности и способу взаимодействия. Например, отправить письмо невозможно до его создания; без синхронизации возникнет состояние гонки; синхронное или асинхронное взаимодействие. Подробные примеры см. на https://connascence.io/</p> </blockquote> <p>Как это можно привязать к практике?</p> <p>Предлагается уменьшать общую взаимозависимость путём декомпозиции на инкапсулированные элементы. В первую очередь удалять те связи, которые нарушают границы инкапсуляции, а для оставшихся связей — уменьшать степень взаимосвязанности, двигаться от динамических связей к статическим. И чем больше расстояние между элементами, тем слабей должна быть степень.</p> <p>Всё равно непонятно, давай рассмотрим пример!</p> <p>Короче, во-первых, нужно убедиться, что <a href="/blog/2025/decomposition-in-the-style-of-quantum-architecture/">декомпозиция сделана правильно</a>. Это уже решит большую часть проблем со связями или, наоборот, выявит недостатки. Во-вторых, выявленные взаимозависимости нужно удалить или свести их влияние к минимуму. Например, вы заметили, как модель одного ограниченного контекста передается без изменений в другой. Что будет, если эта модель поменяется в одном из контекстов? Возможно, стоит задуматься об инкапсуляции транспортного слоя между двумя контекстами? Самый банальный вариант — использовать DTO.</p> <p>Идея оценки связей путём их категоризации вполне разумна, но в оригинальном подходе есть недостатки. Во-первых, весь фокус смещается с архитектуры, которая должна определять правила игры, на детали реализации, качество и чистоту кода. Во-вторых, многие предложенные категории устарели и требуют пересмотра. Например, формы статической взаимозависимости уже давно неактуальны.</p> <p>Возьму на себя смелость сформулировать категории связей, актуальные на сегодняшний день:</p> <ul> <li><em>Явная/неявная.</em> Например, АОП провоцирует множество неявных связей и взаимополаганий.</li> <li><em>Статическая/динамическая.</em> Связь между компонентами предопределена или определяется во время исполнения.</li> <li><em>Асинхронная/синхронная.</em> Есть ли жесткая синхронизация взаимодействия компонентов, управляемая оркеструющим алгоритмом/механизмом.</li> <li><em>Надёжная/ненадёжная.</em> Насколько связь устойчива к различным сбоям и сверхнагрузкам, способна ли она восстанавливаться после такого.</li> </ul> <p>Список можно и нужно уточнять. Однако, как мне кажется, такая категоризация хорошо укладывается в концепцию архитектурных свойств и позволяет прорабатывать каждую категорию в отдельности. Так например, если нужна надёжная связь, то она сопряжена с такими эксплуатационными свойствами как <a href="/blog/2024/reliability-strength-stability/">надёжность, прочность, устойчивость</a> и адаптивность.</p> <hr/> <p>Желаю всем здоровых связей! А в следующий раз разберём, что с этим делать дальше.</p>]]></content><author><name></name></author><category term="post"/><category term="arch"/><summary type="html"><![CDATA[Думаю, многие пытались оценивать качество своей архитектуры, анализируя входящие и исходящие связи между элементами. В этом контексте принято говорить о cohesion и coupling. А что насчёт качества связей?]]></summary></entry><entry><title type="html">Декомпозиция в стиле квантовой архитектуры</title><link href="https://alexmas.github.io//blog/2025/decomposition-in-the-style-of-quantum-architecture/" rel="alternate" type="text/html" title="Декомпозиция в стиле квантовой архитектуры"/><published>2025-11-25T00:00:00+00:00</published><updated>2025-11-25T00:00:00+00:00</updated><id>https://alexmas.github.io//blog/2025/decomposition-in-the-style-of-quantum-architecture</id><content type="html" xml:base="https://alexmas.github.io//blog/2025/decomposition-in-the-style-of-quantum-architecture/"><![CDATA[<p>Какие способы декомпозиции на сервисы мы знаем? И самое главное: как именно сделать такую декомпозицию, в которой мы будем уверены?</p> <p><img src="/assets/img/blog/2025/2025-11-25-quantum-architecture.jpg" alt=""/></p> <p>Например, <a href="https://microservices.io/tags/pattern">К. Ричардсон</a> выделяет два основных подхода к декомпозиции:</p> <ul> <li><em>По бизнес-возможностям (by business capability).</em> Система разбивается на области, в которых бизнес генерирует прибыль. Бизнес-возможности организации определяют то, <strong>чем</strong> она является. Это более стабильное описание, в отличие от того, <strong>как</strong> организация ведёт свой бизнес. Например, обработка платежей будет всегда, и неважно, как именно она будет реализована.</li> <li><em>По поддоменам (by subdomains).</em> Способ декомпозиции системы на основе подходов Domain-driven design (DDD). Каждый поддомен определяет ограниченный контекст (bounded context), который соответствует одному сервису.</li> </ul> <blockquote> <p>Есть и более экзотические методы, которые я описывал ранее в статье “<a href="/blog/2025/msa-decomposition/">Как еще определять границы микросервисов</a>”.</p> </blockquote> <p>И несмотря на то, что всё делаешь “по науке”, продолжает терзать мысль: всё ли правильно и как в этом убедиться.</p> <p>Пожалуй, первое, что приходит на ум, это принципы ООП, сформулированные Р. Мартином, включая SRP (Single Responsibility) и CCP (Common Closure), а также его метрики успешности декомпозиции: <em>абстрактность</em> (соотношение абстрактных элементов к конкретным); <em>нестабильность</em> (соотношение исходящих связей компонента ко всем).</p> <p>Однако всё это мне никогда не давало полной уверенности. Позже я понял причину: они нацелены в первую очередь на техническую сторону вопроса, а не прикладную; оценку существующего кода, а не того, который предстоит написать.</p> <p>Думаю, по этой причине М. Ричардс и Н. Форд ввели понятие <em>архитектурного кванта</em> — уникального набора <a href="/blog/2025/basic-elements-of-an-architectural-framework/">архитектурных свойств</a>, действующих в рамках единицы развертывания — компонента (сервиса). При этом к свойствам предъявляются следующие требования.</p> <ul> <li> <p><em>Непредметный взгляд на проектирование.</em> Функциональные требования определяют, что должно делать приложение, а архитектурные свойства задают эксплуатационные критерии успеха, способствующие реализации требований.</p> </li> <li> <p><em>Влияние на структурные аспекты проектирования.</em> Архитектурное свойство является таковым, если оно влияет на структуру проекта. Например, в одном случае безопасность — это архитектурное свойство, а в другом нет. При обработке платежей через сторонний сервис безопасность важна, но она не повлияет на структуру проекта и будет ограничена технологическими мерами (шифрование, хэширование и т.п.). А вот самостоятельная реализация платежей, возможно, потребует структурной и физической изоляции платёжного сервиса.</p> </li> <li> <p><em>Ключевая или важная роль в успешности решения.</em> Архитектурное свойство является таковым, если оно необходимо для успешной реализации. Поддержка каждого свойства усложняет проектирование, поддержка множества свойств — бессмысленна. Выбранные свойства должны работать на вас, а не наоборот.</p> </li> </ul> <p>О чём это говорит? Производительность, масштабируемость, безопасность, надёжность, доступность — это только слова! В рамках отдельно взятого компонента они могут стать архитектурными свойствами только в том случае, если без них успех проекта невозможен. Понимание этого позволяет сфокусироваться на самых важных вещах и правильно расставить приоритеты.</p> <p>И как это помогает оценить успешность декомпозиции?</p> <p>Возьмите два взаимосвязанных сервиса и определите для них 3 самых важных архитектурных свойства. Каждый сервис — архитектурный квант, он определяет границы действия архитектурных свойств. Мысленно следуя по связи между сервисами, проверьте её адекватность. Если производительный сервис зависит от непроизводительного; безопасный — от небезопасного; масштабируемый — от немасштабируемого и т.д., значит, вы сделали что-то не так.</p> <hr/> <p>Всем добра и правильной декомпозиции! Если тема показалась интересной, поддержите меня. В следующий раз разберём, что есть помимо cohesion и coupling, и зачем это на практике.</p>]]></content><author><name></name></author><category term="post"/><category term="arch"/><summary type="html"><![CDATA[Какие способы декомпозиции на сервисы мы знаем? И самое главное: как именно сделать такую декомпозицию, в которой мы будем уверены?]]></summary></entry><entry><title type="html">Базовые элементы архитектурного фреймворка</title><link href="https://alexmas.github.io//blog/2025/basic-elements-of-an-architectural-framework/" rel="alternate" type="text/html" title="Базовые элементы архитектурного фреймворка"/><published>2025-11-17T00:00:00+00:00</published><updated>2025-11-17T00:00:00+00:00</updated><id>https://alexmas.github.io//blog/2025/basic-elements-of-an-architectural-framework</id><content type="html" xml:base="https://alexmas.github.io//blog/2025/basic-elements-of-an-architectural-framework/"><![CDATA[<p>Рано или поздно каждый уважающий себя разработчик задаётся вопросом: что такое архитектура ПО. И это не просто философия, это попытка систематизировать свой опыт, свои решения, ответить на вопрос, <strong>почему</strong> я поступал так, а не иначе. И как только находим ответ, последующие решения принимаются намного легче и уверенней.</p> <p><img src="/assets/img/blog/2025/2025-11-17-architecture-elements.jpg" alt=""/></p> <p>Многие определения архитектуры хоть и остроумны, но слишком абстрактны, чтобы из этого можно было бы извлечь значимую <em>пользу или найти практическую применимость</em>. Именно по этой причине мне импонирует как М. Ричардс и Н. Форд подошли к ответу на этот вопрос. Они не дают определение, а описывают составляющие архитектуры:</p> <blockquote> <p>Архитектура состоит из <strong>структуры</strong> системы в сочетании со <strong>свойствами</strong> архитектуры, которые должны поддерживаться системой, <strong>архитектурными решениями</strong> и <strong>принципами проектирования</strong>.</p> </blockquote> <p>Как видите, архитектура системы — это не точка на прямой, а точка в многомерном пространстве (согласно авторам — в 4-мерном пространстве). В этом и кроется причина, по которой мы не можем дать архитектуре односложное определение, но можем описать её с разных сторон, одновременно отвечая на вопрос, почему решение именно такое, какое есть. Невозможно составить полное представление об архитектуре системы только по одному измерению, их нужно рассматривать в комплексе.</p> <ol> <li> <p><em>Структура системы (structure of the system)</em> — тип используемого архитектурного стиля (или стилей). Например, микросервисная, многоуровневая, микроядерная и т.д. Стиль задаёт структуру, но не отвечает на вопрос “почему”. Без всего остального — это просто прямоугольники и стрелки.</p> </li> <li> <p><em>Свойства архитектуры (architecture characteristics)</em> — важнейшие черты системы, определяющие критерии успеха. Свойства не связаны с функциональными возможностями системы, но нужны для её корректной работы. Авторы называют их “словами с окончанием <code class="language-plaintext highlighter-rouge">-ость</code>” (англ. <code class="language-plaintext highlighter-rouge">-ility</code>): масштабируемость, производительность, доступность, безопасность и т.д.</p> </li> <li> <p><em>Архитектурные решения (architecture decisions)</em> — правила построения системы и ограничения. Например, “доступ к базе данных возможен только с уровня бизнес-логики”. Естественно, что решения не высечены в камне, и их можно и нужно подвергать сомнению. Главное, чтобы вокруг всего этого был выстроен процесс архитектурного контроля.</p> </li> <li> <p><em>Принципы проектирования (design principles)</em> — верхнеуровневые установки и рекомендации. Например, “для повышения производительности и ослабления связанности отдавать предпочтение асинхронному взаимодействию”; “для улучшения наблюдаемости использовать трассировку всех публичных методов сервиса” и т.п.</p> </li> </ol> <p>Как видите, все эти измерения взаимосвязаны: изменения в одном измерении, скорей всего, отразится в других. Задача архитектора — найти наиболее устойчивое положение в пространстве. И это положение, очевидно, будет совокупностью компромиссов, о которых все так любят говорить. Но главное, что поиск такого положения будет формировать целостный взгляд, <em>структурированный и осознанный ответ</em> на вопрос “почему”.</p> <p>Как это всё связано с практикой и при чём тут фреймворк? Посмотрите на свою систему сквозь призму этих измерений. Для каждого ограниченного контекста определите 3 самых важных архитектурных свойства. Если у каждого контекста свой набор свойств, а у вас “монолит”, тогда вам, возможно, следует задуматься о декомпозиции. Затем посмотрите на свои архитектурные решения и проверьте, способствуют ли они достижению выбранных свойств. А структура и принципы проектирования работают на общее дело? Я думаю, что вы уже поняли, как это работает.</p> <p>Резонный вопрос: “Почему только 4 измерения? Можно больше или меньше?” Больше, наверное, можно, меньше — не думаю. Главное, чтобы за всем этим вы видели технологию, которая позволяет в работе перейти от интуиции к системности.</p> <hr/> <p>После выхода статьи мне задали очень хороший вопрос. Ответ получился достаточно объемным, поэтому включаю его в качестве дополнения.</p> <p><strong>Вопрос:</strong> Не совсем понятно, чем архитектурные решения отличаются от принципов проектирования.</p> <p><strong>Ответ:</strong></p> <p>Ричардс и Форд ставят в центр внимания архитектурные свойства и предлагают выстраивать всё остальное вокруг этого. Иначе говоря, чтобы найти “устойчивое положение” нам нужно с чего-то начать. Фиксируем какой-то набор основных архитектурных свойств, а далее подбираем “координаты” по другим измерениям.</p> <p>Следуя этой концепции они определяют архитектурные решения как то, что влияет на структуру приложения или системы, включая выбор технологических средств, но при условии, что всё это влияет на выбранные архитектурные свойства, способствует их достижению. Также подмечают, что архитектурные решения подразумевают сбор информации для его обоснования, а также описание решения, необходимое и достаточное, чтобы убедить всех ответственных в его правильности. Говоря простым языком, архитектурное решение - это описание способа реализации чего-то в заданном прикладном контексте, но при условии, что это такое решение поддерживает определенное (выбранное) архитектурное свойство. Последнее дополнение проводит тонкую грань между архитектурным решением и техническим. Таким образом, выбор конкретной технологии не всегда архитектурное решение, но и не всегда техническое. Также даётся уточнение, что к архитектурно значимым решениям относятся те, которые влияют на структуру (1-е измерение); архитектурные свойства (2-е измерение), иногда называемые “нефункциональными требованиями”; зависимости (то, что определяет связанность между компонентами); API компонентов и их версионирование.</p> <p>А вот принципы проектирования - это руководство для разработчиков (guideline), рекомендации. Это уже не жёсткие правила, а какие-то “общие правила игры”. Архрешения не могут охватить всевозможные ситуации, поэтому заранее договариваемся о каких-то общих условиях игры. Например, можем сказать, что для при разработке придерживаемся SOLID-принципов; ведём разработку в стиле Domain-Driven Design; пишем приёмочные тесты, подменяя in/out-порты на заглушки; для тестирования публичного API используем контрактное тестирование с помощью Pact и т.д. Если архрешение задаёт чёткое правило (закон) в заданных условиях, то принципы задают общие правила поведения в большинстве возможных ситуаций.</p> <p>Можно ли принципы проектирования оформить в виде архитектурного решения (ADR)? Я думаю, что вполне можно, но, как мне кажется, их нужно структурно отделить. Например, поместить в какой-то отдельный каталог типа <code class="language-plaintext highlighter-rouge">commons</code>. Тогда новый член команды сможет быстро пройтись по базовым принципам, принятым в проекте, а не перебирать всю историю принятых решений.</p> <p>Нужно ли отделять архитектурные решения от технических? Или же все решения хранить в общей куче? В идеале, лучше отделять, чтобы чётко видеть то, что действительно влияет на архитектурные свойства. С другой стороны, такое разделение требует от нас максимальной дисциплинированности и педантичности, что на практике трудно достижимо. Наверное, компромиссным решением было бы введение в описание какого-то “уровня важности” (перечисление). И при выборе уровня важности можно было бы давать пояснение, что он значит. Я видел, что в крупных компаниях есть такая категоризация и отдельный процесс согласования решений для каждого уровня важности.</p>]]></content><author><name></name></author><category term="post"/><category term="arch"/><summary type="html"><![CDATA[Рано или поздно каждый уважающий себя разработчик задаётся вопросом: что такое архитектура ПО. И это не просто философия, это попытка систематизировать свой опыт, свои решения, ответить на вопрос, почему я поступал так, а не иначе. И как только находим ответ, последующие решения принимаются намного легче и уверенней.]]></summary></entry><entry><title type="html">Меры предосторожности при работе с РСУБД</title><link href="https://alexmas.github.io//blog/2025/safety-instruction-rdbms/" rel="alternate" type="text/html" title="Меры предосторожности при работе с РСУБД"/><published>2025-11-11T00:00:00+00:00</published><updated>2025-11-11T00:00:00+00:00</updated><id>https://alexmas.github.io//blog/2025/safety-instruction-rdbms</id><content type="html" xml:base="https://alexmas.github.io//blog/2025/safety-instruction-rdbms/"><![CDATA[<p>В пылу сражения легко забыть базовые меры предосторожности. Именно по этой причине разговоры о подобных вещах всегда актуальны. Предлагаю пройтись по базовым рекомендациям при работе с РСУБД. За основу взят зажигательный доклад “<a href="https://highload.ru/moscow/2025/abstracts/16855">Хайлоад на ровном месте</a>” и дополнен моими комментариями.</p> <p><img src="/assets/img/blog/2025/2025-11-11-safety-instruction-rdbms.jpg" alt=""/></p> <ul> <li> <p>Количество соединений с БД — это ограниченный ресурс, который контролируется как со стороны БД, так и со стороны приложения. Чем больше параллельных обращений к БД, тем больше должен быть пул соединений; иначе тот, кому не досталось соединения, зависнет до появления свободного соединения. Это значит, что будут таймауты, рост числа wait-потоков, рост потребления памяти (как минимум, на стек), рост потребления CPU (как минимум, на переключение контекста) и множество ярких эмоций.</p> </li> <li> <p>Idle-соединение — это неактивное соединение, которое захватило приложение, но не использует его. Например, захват соединения, затем длительные вычисления (или даже <em>поход во внешние сервисы</em>), и только в конце работа с БД. При таком подходе пул соединений будет израсходован очень быстро, и указанные выше проблемы возникнут практически сразу.</p> </li> <li> <p>Idle-in-transaction-соединение — это idle-соединение, в котором начали выполнение транзакции. Чаще всего такое провоцируют фреймворки. Например, аннотация <code class="language-plaintext highlighter-rouge">@Transactional</code> была помещена на верхний уровень процесса обработки запроса и захватывает не только работу с БД. Ко всем вышеуказанным проблемам сюда можно смело докидывать увеличение времени транзакции, длительные блокировки в БД, расходы на хранение версий (MVCC), раздувание WAL (Wall-Ahead Log).</p> </li> </ul> <blockquote> <p>Для “защиты” PostgreSQL от неблагонадёжных приложений разработан <a href="https://github.com/pgbouncer/pgbouncer">PgBouncer</a>, который проксирует взаимодействие с базой с целью пулинга соединений. Он позволяет активным соединениям вытеснять idle-соединения (но не idle-in-transaction), что увеличивает пропускную способность.</p> </blockquote> <ul> <li> <p>Если транзакция открывается только для чтения (SELECTs), то при <a href="/blog/2025/transaction-isolation-issues/">уровне изоляции</a> Read Committed её лучше убрать, т.к. “толку” от неё не будет, и это позволит избавиться от idle-in-transaction-соединений. А вот если нужен “толк”, тогда нужно повышать уровень изоляции, как минимум, до Repeatable Read, но такое нужно далеко не каждому.</p> </li> <li> <p>Для минимизации времени блокировок в БД все UPDATEs в коде нужно сместить ближе к месту закрытия транзакции. Конечно, это не избавит от idle-in-transaction-соединений, но это лучше, чем ничего.</p> </li> <li> <p>Пессимистичную блокировку следует применять, если много коллизий (высокая конкурентность при изменениях). Однако часто достаточно оптимистичной блокировки, которая избавляет от необходимости явного открытия обрамляющей транзакции, следовательно, от описанных выше проблем. Если же пессимистичная блокировка всё-таки нужна, то её можно реализовать не на уровне БД, а с помощью внешних механизмов (например, key-value-хранилищ).</p> </li> <li> <p>Медленные запросы могут исчерпать пул соединений, даже если таких запросов не очень много. Поэтому контролируем время выполнения запросов и анализируем планы запросов (explain). Частые проблемы: нет индексов на внешние ключи (foreign keys); используется <a href="https://jpoint.ru/archive/2022/talks/5d1a6b1be31c37d0e2b38f36b440fe15/">антипаттерн OrIsNull</a>; используется offset pagination (часто в сочетании с OrIsNull) вместо <a href="https://jpoint.ru/archive/2023/talks/7c6a25d123b441c68a48c1da157e3f38/">keyset pagination</a>; выбираются лишние данные (особенно <a href="https://www.postgresql.org/docs/current/storage-toast.html">TOAST</a>).</p> </li> </ul>]]></content><author><name></name></author><category term="post"/><category term="tip"/><category term="dev"/><category term="devops"/><summary type="html"><![CDATA[В пылу сражения легко забыть базовые меры предосторожности. Именно по этой причине разговоры о подобных вещах всегда актуальны. Предлагаю пройтись по базовым рекомендациям при работе с РСУБД. За основу взят зажигательный доклад “Хайлоад на ровном месте” и дополнен моими комментариями.]]></summary></entry><entry><title type="html">Ключевые темы HighLoad++ 2025</title><link href="https://alexmas.github.io//blog/2025/highload-2025/" rel="alternate" type="text/html" title="Ключевые темы HighLoad++ 2025"/><published>2025-11-10T00:00:00+00:00</published><updated>2025-11-10T00:00:00+00:00</updated><id>https://alexmas.github.io//blog/2025/highload-2025</id><content type="html" xml:base="https://alexmas.github.io//blog/2025/highload-2025/"><![CDATA[<p>2 дня конференции, 5000+ участников, 10 параллельных треков, 121 доклад, 10 мастер-классов и, конечно же, Fail-митап. (На котором, я, надеюсь, не сильно зафэйлился.) Вот таким стал прошедший HL++. Очень много информации, которую нужно обработать и структурировать.</p> <p><img src="/assets/img/blog/2025/2025-11-10-highload-2025.jpg" alt=""/></p> <p>Из примечательного. Онтико продолжает активно развивать тему воркшопов и мастер-классов. Их стало значительно больше, и они были оба дня. Это очень продуктивный формат, предполагающий постоянный интерактив. На будущее особенно рекомендую посещать те из них, которые не записываются.</p> <p>Много докладов было про AI (16). Очевидно, что эта тема стремительно врывается в нашу жизнь и диктует новые правила игры. Пока многие практические применения AI выглядят как обучение медведя катанию на велосипеде с целью его дальнейшей отправки на олимпиаду. Однако очень хорошо, что компании пытаются найти границы применимости AI. Короче, держим хвост по ветру и не теряем бдительности.</p> <p>Традиционно для HL++ много докладов про архитектуру и масштабируемость (34), про мои любимые базы данных (17), низкоуровневые и хардкорные оптимизации. Что-то я успел посмотреть очно, но большая часть находится в моём бэклоге.</p> <p>Были доклады, которые дали ответы на интересующие меня вопросы или подтвердили мою точку зрения. Наверняка, обо всём этом я напишу отдельные посты.</p> <p>А ещё для нас смертных устроили открытую встречу с министром цифрового развития М.И. Шадаевым. Разговор получился долгим и достаточно откровенным. Надеюсь, что видео будет доступно в ближайшее время.</p> <p>На финальной фотке виновники всего торжества, включая меня. Очень рад, что стал частью этой команды и мероприятия и, надеюсь, смог сделать его чуточку лучше.</p>]]></content><author><name></name></author><category term="post"/><category term="conf"/><summary type="html"><![CDATA[2 дня конференции, 5000+ участников, 10 параллельных треков, 121 доклад, 10 мастер-классов и, конечно же, Fail-митап. (На котором, я, надеюсь, не сильно зафэйлился.) Вот таким стал прошедший HL++. Очень много информации, которую нужно обработать и структурировать.]]></summary></entry><entry><title type="html">Как начать структурировать опыт</title><link href="https://alexmas.github.io//blog/2025/how-to-structure-experience/" rel="alternate" type="text/html" title="Как начать структурировать опыт"/><published>2025-10-31T00:00:00+00:00</published><updated>2025-10-31T00:00:00+00:00</updated><id>https://alexmas.github.io//blog/2025/how-to-structure-experience</id><content type="html" xml:base="https://alexmas.github.io//blog/2025/how-to-structure-experience/"><![CDATA[<p>Друзья, а вы пробовали коротко, ёмко и понятно описать причину технической проблемы или неудачи? Если нет, то я очень рекомендую. Это упражнение позволяет отрефлексировать и структурировать только что полученный опыт. В этот момент вы занимаетесь огранкой алмаза, золотодобычей своего профессионализма. На входе у вас тонны грубой руды, а на выходе один прекрасный алмаз, бесценная частичка ваших знаний. В итоге насмотренность конвертируется в повышение квалификации.</p> <p><img src="/assets/img/blog/2025/2025-10-28-fail-meetup.jpeg" alt=""/></p> <p>Упражнение очень простое. Заведите себе “дневник”, в котором в свободном, но желательно единообразном формате, описывайте ситуацию, последовательность ваших действий, причину произошедшего и итоговое решение. Описание должно быть кратким, структурированным, но очень ёмким и понятным. Через некоторое время вы обязательно заметите положительный эффект. Как минимум, сможете блеснуть зрелостью своего опыта или получить больше уверенности на собеседовании.</p> <p>На следующей неделе, 6 и 7 ноября пройдёт крупнейшая IT-конференция для разработчиков высоконагруженных систем — <a href="https://highload.ru/">HighLoad++</a>. Я буду выступать на <a href="https://highload.ru/moscow/2025/abstracts/17079">Fail-митапе</a>, где расскажу про свой самый крупный профессиональный фэйл за прошедшие 1.5 года. Многие знают, что подобные рассказы часто оказываются более ценными, чем красочный доклад про успешный успех. Fail-секция — это шанс быстро получить “огранённый” ценный опыт и не повторить чужих ошибок. Для меня этот формат в новинку, однако я надеюсь, что рассказ будет не только интересным и смешным, но и полезным.</p> <p>Если будете вместе со мной на конференции, пишите. Познакомимся ближе, буду рад общению. Как минимум, приходите на Fail-митап.</p>]]></content><author><name></name></author><category term="post"/><category term="tip"/><category term="conf"/><summary type="html"><![CDATA[Друзья, а вы пробовали коротко, ёмко и понятно описать причину технической проблемы или неудачи? Если нет, то я очень рекомендую. Это упражнение позволяет отрефлексировать и структурировать только что полученный опыт. В этот момент вы занимаетесь огранкой алмаза, золотодобычей своего профессионализма. На входе у вас тонны грубой руды, а на выходе один прекрасный алмаз, бесценная частичка ваших знаний. В итоге насмотренность конвертируется в повышение квалификации.]]></summary></entry><entry><title type="html">Вспомогательная таблица для ускорения выборки</title><link href="https://alexmas.github.io//blog/2025/data-seive/" rel="alternate" type="text/html" title="Вспомогательная таблица для ускорения выборки"/><published>2025-10-28T00:00:00+00:00</published><updated>2025-10-28T00:00:00+00:00</updated><id>https://alexmas.github.io//blog/2025/data-seive</id><content type="html" xml:base="https://alexmas.github.io//blog/2025/data-seive/"><![CDATA[<p>Сегодня поделюсь методом оптимизации выборки больших данных, который кажется очевидным, но не всегда приходит в голову. Этот подход я использовал в связке с ClickHouse, однако он подходит для большинства хранилищ данных.</p> <p><img src="/assets/img/blog/2025/2025-10-28-data-seive.jpeg" alt=""/></p> <h2 id="контекст">Контекст</h2> <p>Имеется агрегат, с которым может быть связано много данных, которые накапливаются с течением длительного времени. Например, пациент и его документы; датчик и его показания.</p> <p>Обычно такие данные хранят в табличном виде, и в рамках такой таблицы есть связка между идентификатором агрегата, ассоциированным элементом и временем создания элемента. Например, таблица документов хранит ссылку на пациента и время создания документа; таблица показаний хранит ссылку на датчик и время снятия показаний.</p> <p>Вполне вероятно, что в целях нормального распределения данных, их партиционирование будет выполнено по времени создания элементов данных (например, времени создания документа; времени снятия показаний). Гранулярность партиционирования определяется выбранной БД, объемом данных и интенсивностью их поступления.</p> <p>Пример таблицы с показаниями датчиков в ClickHouse:</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">history</span> <span class="p">(</span>
  <span class="n">tag</span> <span class="n">String</span><span class="p">,</span>
  <span class="nb">date</span> <span class="nb">Date</span> <span class="k">DEFAULT</span> <span class="n">toDate</span><span class="p">(</span><span class="nb">time</span><span class="p">),</span>
  <span class="nb">time</span> <span class="n">DateTime64</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s1">'UTC'</span><span class="p">),</span>
  <span class="n">value</span> <span class="n">Float64</span>
<span class="p">)</span>
<span class="n">ENGINE</span> <span class="o">=</span> <span class="n">MergeTree</span><span class="p">()</span>
<span class="k">PARTITION</span> <span class="k">BY</span> <span class="n">toYYYYMM</span><span class="p">(</span><span class="nb">date</span><span class="p">)</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="nb">date</span><span class="p">,</span> <span class="nb">time</span><span class="p">)</span>
</code></pre></div></div> <h2 id="проблемы">Проблемы</h2> <p>В системе очень часто (или всегда) запрашивают данные без указания временного диапазона, но, возможно, с указанием дополнительных фильтров. Например, получить документы по пациенту у терапевта; получить показания датчика со значениями выше нормы.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">tag</span><span class="p">,</span> <span class="nb">time</span><span class="p">,</span> <span class="n">value</span>
<span class="k">FROM</span> <span class="n">history</span>
<span class="k">WHERE</span> <span class="n">tag</span> <span class="o">=</span> <span class="p">:</span><span class="n">tag</span> <span class="k">AND</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="p">:</span><span class="n">value</span>
</code></pre></div></div> <p>Без указания временных границ приходится сканировать все партиции за всё время. В результате запрос выполняется очень долго и создает большую нагрузку на I/O.</p> <h2 id="решение">Решение</h2> <p>Создать производную таблицу с “подсказками”, по которым можно будет существенно ограничить количество партиций при выборке данных. По такой таблице можно определять наличие данных у агрегата за весь период его существования. Например, дни, за которые у пациента/датчика есть документы/показания.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="n">MATERIALIZED</span> <span class="k">VIEW</span> <span class="n">history_info</span>
<span class="n">ENGINE</span> <span class="o">=</span> <span class="n">ReplacingMergeTree</span><span class="p">()</span>
<span class="k">PARTITION</span> <span class="k">BY</span> <span class="n">toYYYYMM</span><span class="p">(</span><span class="nb">date</span><span class="p">)</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="nb">date</span><span class="p">)</span>
<span class="n">POPULATE</span>
<span class="k">AS</span>
<span class="k">SELECT</span> <span class="n">tag</span><span class="p">,</span> <span class="nb">date</span>
<span class="k">FROM</span> <span class="n">history</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">tag</span><span class="p">,</span> <span class="nb">date</span>
</code></pre></div></div> <p>По такой таблице, например, можно очень быстро найти левую границу данных:</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">min</span><span class="p">(</span><span class="nb">date</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">history_info</span>
<span class="k">WHERE</span> <span class="n">tag</span> <span class="o">=</span> <span class="p">:</span><span class="n">tag</span>
</code></pre></div></div> <p>Эту информацию можно использовать как подсказку в основном запросе:</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">tag</span><span class="p">,</span> <span class="nb">time</span><span class="p">,</span> <span class="n">value</span>
<span class="k">FROM</span> <span class="n">history</span>
<span class="k">WHERE</span> <span class="n">tag</span> <span class="o">=</span> <span class="p">:</span><span class="n">tag</span> <span class="k">AND</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="p">:</span><span class="n">value</span>
  <span class="k">AND</span> <span class="nb">date</span> <span class="o">&gt;=</span> <span class="p">(</span>
    <span class="k">SELECT</span> <span class="k">min</span><span class="p">(</span><span class="nb">date</span><span class="p">)</span>
    <span class="k">FROM</span> <span class="n">history_info</span>
    <span class="k">WHERE</span> <span class="n">tag</span> <span class="o">=</span> <span class="p">:</span><span class="n">tag</span>
  <span class="p">)</span>
</code></pre></div></div> <p>Подобное решение можно адаптировать и под другие варианты партиционирования данных, а производная таблица “подсказок” может быть более или менее информативной. Основная её цель — это существенно сократить объем выборки без потери качества результата.</p> <h2 id="плюсы">Плюсы</h2> <ul> <li>Существенное ускорение времени выполнения запроса.</li> <li>Существенное снижение нагрузки на I/O.</li> </ul> <h2 id="минусы">Минусы</h2> <ul> <li>Усложнение кода приложения для создания производной таблицы, наполнения её данными и поддержания их в актуальном состоянии. Если данная проблема решается средствами СУБД, как, например, в ClickHouse, то данный минус несущественный.</li> <li>Увеличение размера хранимых данных.</li> </ul>]]></content><author><name></name></author><category term="post"/><category term="tip"/><category term="db"/><summary type="html"><![CDATA[Сегодня поделюсь методом оптимизации выборки больших данных, который кажется очевидным, но не всегда приходит в голову. Этот подход я использовал в связке с ClickHouse, однако он подходит для большинства хранилищ данных.]]></summary></entry></feed>